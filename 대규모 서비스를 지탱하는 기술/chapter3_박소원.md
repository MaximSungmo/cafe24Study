### OS 캐시와 분산
<br>

#### I/O 대책에 대한 기반은 OS에 있다.

- 원래 OS에는 기본적으로 디스크 내의 데이터에 빠르게 access할 수 있도록 하는 구조가 갖춰져 있다. OS는 캐시 구조와 메모리를 이용해서 디스크 액세스를 줄인다.  


````
가상메모리란?

실제 RAM(주 기억장치)보다 큰 메모리 영역을 제공하는 방법으로 사용됨

프로세스들이 CPU랑 메인메모리를 공유하는데 그때 CPU 병목이 생기면 그냥 속도가 느려질뿐 치명적인 오류는 나오지 않지만 메모리가 병목같이 지나친 요인이 생기면 논리와 무관하게 오류가 나기때문에 이것을 방지하기 위한 것이 가상 메모리

OS는 메모리를 직접 프로세스에 넘기는 것이 아니라 일단 커널 내에서 메모리를 추상화하고 있다는 점 이것이 바로 가상 메모리 구조

물리적으로 부족한 메인 메모리의 용량 확보를 위해 하드디스크(HDD)를 이용해서 당장 쓰지않는 데이터를 집어넣고 가상메모리로 사용


굳이 돈을 들여서 또 램을 구매하고 싶지 않은 사용자 같은 경우에 가상메모리를 늘려 해결할 수 있다. 지금 사용하고 있는 디스크의 일정 용량을 마치 램 메모리처럼 활용하는 방법이다. 그래서 디스크의 속도를 따라가기 때문에 실제 메모리보다 현저하게 느리긴 함


````


#### 프로세스가 디스크로부터 데이터 읽어내는 과정

1.	우선 디스크에 가서 4KB(메모리를 1바이트씩 엑세스x 적당히 블록으로 확보함) 크기의 블록을 읽어냄
2.	메모리상에 씀
3.	프로세스에게 가상 address로 알려줌
4.	프로세스가 가상 address를 통해 접근


재부팅 안하는게 캐시에 쌓인 데이터 쓰기 좋아서 속도가 빠름

```
페이지 교체 알고리즘

FIFO(First In First Out)

 - 각 페이지가 주기억장치에 적재될 때마다 그때의 시간을 기억시켜 가장 먼저

 LRU(Least Recently Used)

  - 최근에 가장 오랫동안 사용하지 않은 페이지를 교체하는 기법

  - 각 페이지마다 계수기나 스택을 두어 현 시점에서 가장 오랫동안 사용하지 않은,

 즉 가장 오래 전에 사용된 페이지를 교체한다.

 LFU(Least Frequently Used)

 - 사용 빈도가 가장 적은 페이지를 교체하는 기법

```

- 캐시 이외의 메모리가 필요해지면 오래된 캐시가 파기된다.

#### 4GB 파일을 전부 읽게 되면?
->한번에 전부 가져오는게 아니라 4KB 블록만을 캐싱하므로 특정 파일의 일부분만 읽어낸 부분만을 캐싱할 수 있음

cache 그림

#### 단순하게 대수만 늘려서는 확장성을 확보할 수 없다.

- 메모리를 증설 할 수 없는 경우에 데이터를 분할해서 각각의 서버에 위치시키는 것을 고려해본다
- 데이터를 적절하게 분할하면 단순히 서버 대수를 늘린만큼 디스크 I/O횟수만 줄어드는 것이 아니라. 캐시에 올릴 데이터의 비율이 늘어나므로 상당한 전송량 향상을 기대할 수 있다.

캐싱하지 못한 데이터는 당연히 직접 디스크에서 읽어들인다

Ex) 유지보수 등으로 서버 재부팅하면 캐시 메모리에 있는거 다 날라가서 많은 디스크 I/O를 겪게 된다
